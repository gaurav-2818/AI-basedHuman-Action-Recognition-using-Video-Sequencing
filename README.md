# AI-basedHuman-Action-Recognition-using-Video-Sequencing
Vision-based human action recognition has received increasing attentions in computer vision and has made significant progress in recent years. It consists in labelling small video sequences with action classes. The most common approach involves two steps: feature extraction and classification.
This project surveys extensively the current progress made toward video-based human
activity recognition. Three aspects for human activity recognition are addressed including core
technology, human activity recognition systems, and applications from low-level to high-level
representation.
In the core technology, three critical processing stages are thoroughly discussed mainly:
human object segmentation, feature extraction and representation, activity detection and
classification algorithms.
In the human activity recognition systems, three main types are mentioned, including single
person activity recognition, multiple people interaction and crowd behavior, and abnormal
activity recognition.
In sequential approaches, traditional statistical techniques are initially proposed for handling
human activity recognition tasks. Using principle component analysis (PCA) based on singular
value decompositions (SVD), Yacoob processed one input as a signal, with sequential statistical
features extractions, indicating all behaviors are the linear combination with different weighted
statistical features. Lublineraman et al. also proposed a linear time invariant (LTI) system based
on Fourier descriptors for learning features of dynamic changes. The LTI model can also classify
a new input with similar features, such as slow walk and fast walk.
![image](https://user-images.githubusercontent.com/117379142/235195614-19599adf-ad11-475d-9aa7-c37f399adcf0.png)
